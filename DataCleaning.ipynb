{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5899b3b7-108a-4989-99fa-675cecb2460e",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c57cf2d-5e53-412a-a35b-f505244c1340",
   "metadata": {},
   "source": [
    "In this notebook our goal will is going to be to prepare all data needed for training/testing our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94303855-36d9-46c0-b604-10c6f5594760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from utils.Utils import get_min_dimensions,check_duplicates,remove_duplicates, breeds, extract_breed, process_file\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2c0f75-ab56-42b0-8e45-e7518e91dd1d",
   "metadata": {},
   "source": [
    "### 1. Reorganize images in folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e170d672-fb39-4db2-b514-a09aa1223290",
   "metadata": {},
   "source": [
    "In this step, we'll group images in folder by breeds to ensure that both train/test have all breeds. If we had skipped this step, we could have stored breeds in test that had not been trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0faaa90-7628-4c0c-9d52-44eed5a43511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breed folders created:\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from shutil import copy\n",
    "\n",
    "# Path to your data folder\n",
    "data_folder_path = \"data\"\n",
    "\n",
    "# Create a dictionary to store breeds and corresponding folder paths\n",
    "breed_folders = {}\n",
    "\n",
    "# Regular expression pattern to extract breed name\n",
    "pattern = re.compile(r'(.+)_\\d+\\.jpg')\n",
    "\n",
    "# Iterate through each file in the data folder\n",
    "for filename in os.listdir(data_folder_path):\n",
    "    # Match the pattern to extract the breed name\n",
    "    match = pattern.match(filename)\n",
    "    \n",
    "    if match:\n",
    "        breed_name = match.group(1)\n",
    "        \n",
    "        # Create a folder for the breed if it doesn't exist\n",
    "        if breed_name not in breed_folders:\n",
    "            breed_folder = os.path.join(data_folder_path, breed_name)\n",
    "            os.makedirs(breed_folder, exist_ok=True)\n",
    "            breed_folders[breed_name] = breed_folder\n",
    "        \n",
    "        # Copy the file to the respective breed folder\n",
    "        src_path = os.path.join(data_folder_path, filename)\n",
    "        dest_path = os.path.join(breed_folders[breed_name], filename)\n",
    "        copy(src_path, dest_path)\n",
    "        \n",
    "        # Remove the file from the data folder\n",
    "        os.remove(src_path)\n",
    "\n",
    "# Print the list of breed folders\n",
    "print(\"Breed folders created:\\n\")\n",
    "print(100*'*')\n",
    "for breed_name, folder_path in breed_folders.items():\n",
    "    print(f\"{breed_name}: {folder_path}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff55c94b-70ab-4424-8508-ed11797f20a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'train' created successfully at 'data/train'\n",
      "Folder 'test' created successfully at 'data/test'\n",
      "\n",
      "Processing folder: .ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "files_folder=200\n",
    "train_ratio=0.8\n",
    "num_files=train_ratio*files_folder\n",
    "\n",
    "data_folder=\"data/\"\n",
    "train_dest=\"data/train/\"\n",
    "test_dest=\"data/test/\"\n",
    "\n",
    "# Specify the path where you want to create the new folders\n",
    "base_path = data_folder\n",
    "\n",
    "# Create \"train\" folder\n",
    "train_path = os.path.join(base_path, \"train\")\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "print(f\"Folder 'train' created successfully at '{train_path}'\")\n",
    "\n",
    "# Create \"test\" folder\n",
    "test_path = os.path.join(base_path, \"test\")\n",
    "os.makedirs(test_path, exist_ok=True)\n",
    "print(f\"Folder 'test' created successfully at '{test_path}'\\n\")\n",
    "\n",
    "for folder in os.listdir(data_folder):\n",
    "    folder_path = os.path.join(data_folder, folder)\n",
    "    if os.path.isdir(folder_path) and folder not in (\"train\",\"test\"):\n",
    "        i=0\n",
    "        print(\"Processing folder: \"+str(folder))\n",
    "        for filename in os.listdir(folder_path):\n",
    "            img = os.path.join(folder_path, filename)\n",
    "            if i<num_files:\n",
    "                dest_path=train_dest\n",
    "            else:\n",
    "                dest_path=test_dest\n",
    "            copy(img,dest_path)\n",
    "            os.remove(img)\n",
    "            i=i+1\n",
    "        os.rmdir(folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f6bae1-465f-4ed0-845a-7c64871d14de",
   "metadata": {},
   "source": [
    "Now, we have all images in a 80/20 ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80968615-009c-41c0-be40-07b1162f1932",
   "metadata": {},
   "source": [
    "## 2. Store labels in a csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc1da14-98dd-49f7-8fa9-8fc361f8afd7",
   "metadata": {},
   "source": [
    "Another problem we need to solve is that we have all labels in different sources. We have class and breeds id's in txt files, while bounding boxes are in xml files and trimaps in another location. Our goal is to try to unify most of our data ina  single csv, while trimaps are going to stay in a different folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20f4269e-dbf5-4bb8-9ebe-46e9299aa57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "\n",
    "# Specify the paths for the train and test folders\n",
    "train_folder_path = \"data/train\"\n",
    "test_folder_path = \"data/test\"\n",
    "\n",
    "# Specify the path for the output CSV file\n",
    "train_output = \"data/y_train.csv\"\n",
    "test_output = \"data/y_test.csv\"\n",
    "\n",
    "# Process files in the train folder\n",
    "for filename in os.listdir(train_folder_path):\n",
    "    file_path = os.path.join(train_folder_path, filename)\n",
    "    process_file(file_path, train_output)\n",
    "\n",
    "# Process files in the test folder\n",
    "for filename in os.listdir(test_folder_path):\n",
    "    file_path = os.path.join(test_folder_path, filename)\n",
    "    process_file(file_path, test_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd170b5f-226e-4847-af7f-10433a976d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2c88afe-d00c-4120-b5f6-bd7b4f548f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate IDs found:\n",
      "Train.csv has 0 duplicated rows\n",
      "Test.csv has 3 duplicated rows\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "# Specify the path for the existing CSV file\n",
    "existing_csv_path = \"data/y_train.csv\"\n",
    "existing_csv_path2 = \"data/y_test.csv\"\n",
    "# Check for duplicates\n",
    "train_duplicates = check_duplicates(existing_csv_path)\n",
    "test_duplicates = check_duplicates(existing_csv_path2)\n",
    "\n",
    "if train_duplicates or test_duplicates:\n",
    "    print(\"Duplicate IDs found:\")\n",
    "    print(\"Train.csv has \"+str(len(train_duplicates))+\" duplicated rows\")\n",
    "    print(\"Test.csv has \"+str(len(test_duplicates))+\" duplicated rows\")\n",
    "else:\n",
    "    print(\"No duplicates found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66acb114-c606-4640-9fa6-33ac61e09001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated rows removed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the paths for the existing and output CSV files\n",
    "existing_csv_path = \"data/y_train.csv\"\n",
    "output_csv_path = \"data/y_train.csv\"\n",
    "\n",
    "# Remove training duplicated rows\n",
    "remove_duplicates(existing_csv_path, output_csv_path)\n",
    "\n",
    "existing_csv_path = \"data/y_test.csv\"\n",
    "output_csv_path = \"data/y_test.csv\"\n",
    "\n",
    "# Remove esting duplicated rows\n",
    "remove_duplicates(existing_csv_path, output_csv_path)\n",
    "\n",
    "print(\"Duplicated rows removed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e03ea5-c361-4915-94e8-bda7276f6d35",
   "metadata": {},
   "source": [
    "As we can see, there are images that have no annotations. We should complete them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818362fc-3ec9-4f9d-9175-a2d89c102a62",
   "metadata": {},
   "source": [
    "## 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f99e2b-e5b6-4039-9e34-3d8449decafd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
